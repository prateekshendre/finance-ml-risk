# ğŸ¤– Machine Learning for Financial Risk
End-to-end **credit default and counterparty risk modeling pipeline** with explainability and governance.  
This repo contains a reproducible workflow from ingestion through model explainability and a minimal deployment path.  

---
## ğŸš€ What This Project Does
* **Ingests** raw loan or counterparty data and produces cleaned feature sets  
* **Encodes & scales** variables using reproducible preprocessing pipelines  
* **Trains** logistic regression, random forest, and gradient boosting models  
* **Validates** performance with time-based splits and cross-validation  
* **Explains** model behavior with SHAP for global and local interpretability  
* **Generates** model cards and validation reports for governance  

---
## ğŸ“‚ Data
* **Sample datasets** live in `data/examples/` for quick testing  
* Real data should be ingested via `src/ingestion.py` and stored securely in `data/feature_store/`  
* Clean CSV/parquet snapshots enable reproducible backtests and validations  

---
## ğŸ›  Methods & Tools
* **pandas, numpy** â€“ data pipelines and transforms  
* **scikit-learn** â€“ preprocessing, baseline models, validation  
* **xgboost / lightgbm** â€“ boosted trees  
* **shap** â€“ explainability  
* **mlflow** â€“ experiment tracking  
* **pytest** â€“ testing  
* **Docker** â€“ packaging  

---
## ğŸ“ Repository Layout

```

finance-ml-risk/  
â”œâ”€â”€ data/  
â”‚   â”œâ”€â”€ examples/                 # sample CSVs  
â”‚   â””â”€â”€ feature_store/            # engineered features  
â”œâ”€â”€ configs/  
â”‚   â””â”€â”€ train.yaml                # training config  
â”œâ”€â”€ notebooks/  
â”‚   â””â”€â”€ eda_feature_engineering.ipynb  
â”œâ”€â”€ src/  
â”‚   â”œâ”€â”€ ingestion.py              # raw to cleaned  
â”‚   â”œâ”€â”€ features.py               # feature engineering  
â”‚   â”œâ”€â”€ pipeline.py               # preprocessing pipeline  
â”‚   â”œâ”€â”€ train.py                  # training entry  
â”‚   â”œâ”€â”€ evaluate.py               # validation metrics  
â”‚   â”œâ”€â”€ explainability.py         # SHAP reports  
â”‚   â””â”€â”€ predict.py                # inference API  
â”œâ”€â”€ experiments/                  # MLflow logs  
â”œâ”€â”€ outputs/  
â”‚   â”œâ”€â”€ models/  
â”‚   â””â”€â”€ reports/  
â”œâ”€â”€ reports/  
â”‚   â”œâ”€â”€ model_card_template.md  
â”‚   â””â”€â”€ validation_report_template.md  
â”œâ”€â”€ scripts/  
â”‚   â””â”€â”€ run_training.sh  
â”œâ”€â”€ tests/  
â”‚   â”œâ”€â”€ test_pipeline.py  
â”‚   â””â”€â”€ test_features.py  
â”œâ”€â”€ .github/  
â”‚   â””â”€â”€ workflows/ci.yml  
â”œâ”€â”€ requirements.txt  
â”œâ”€â”€ Dockerfile  
â”œâ”€â”€ README.md  
â”œâ”€â”€ LICENSE  
â””â”€â”€ .gitignore

```

---
## ğŸ–¼ Key Outputs
1. **Performance Metrics** â€“ ROC AUC, precision-recall, calibration  
2. **SHAP Explainability Reports** â€“ global & local explanations  
3. **Feature Stability** â€“ PSI across time buckets  
4. **Model Card** â€“ intended use, limitations, risks  
5. **Validation Report** â€“ compliance-ready documentation  

---
## âš¡ How to Run Locally
1. Clone repo  
   ```
   git clone https://github.com/your-username/finance-ml-risk.git  
   cd finance-ml-risk
   ```

2. Create virtual environment  
   ```
   python -m venv venv  
   source venv/bin/activate   # on Windows: venv\Scripts\activate
   ```
   
3. Install dependencies  
   ```
   pip install -r requirements.txt
   ```

4. Prepare data  
   ```
   python src/ingestion.py --input data/examples/raw.csv --out data/feature_store/clean.parquet
   ```

5. Train model  
   ```
   python src/train.py --config configs/train.yaml
   ```

6. Evaluate & explain  
   ```
   python src/evaluate.py --model outputs/models/model.pkl --data data/feature_store/clean.parquet  
   python src/explainability.py --model outputs/models/model.pkl --data data/feature_store/clean.parquet --out outputs/reports/shap_summary.html
   ```

7. Serve model (Docker)  
   ```
   docker build -t finance-ml-risk .  
   docker run --rm -p 8080:8080 finance-ml-risk
   ```

---
## ğŸ“Œ Example Training Config
```
train.yaml  
seed: 42  
model:  
  type: xgboost  
  params:  
    n_estimators: 200  
    learning_rate: 0.05  
    max_depth: 6  
data:  
  train_start: 2018-01-01  
  train_end: 2021-12-31  
  val_start: 2022-01-01  
  val_end: 2022-12-31  
paths:  
  raw_input: data/examples/raw.csv  
  feature_store: data/feature_store/clean.parquet  
  outputs: outputs/  
features:  
  categorical: [sector, region]  
  numeric: [loan_amount, ltv, dsr]
``` 

---
## ğŸ”® Next Steps
* Add **drift monitoring** with PSI  
* Automate retraining with CI/CD gates  
* Build lightweight monitoring dashboard  
* Integrate with online feature store  

---
## ğŸ“œ License
MIT License
